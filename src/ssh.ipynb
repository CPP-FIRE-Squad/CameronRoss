{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paramiko\n",
    "\n",
    "def ssh_into_remote():\n",
    "    # SSH connection parameters\n",
    "    host = 'lilmac.local'\n",
    "    username = 'cameronross'\n",
    "    password = '0812'\n",
    "    # SSH client setup\n",
    "    ssh_client = paramiko.SSHClient()\n",
    "    ssh_client.connect(host, username=username, password=password)\n",
    "    # Execute the Python code remotely\n",
    "    commands = [\n",
    "        \"from stellarutil import Simulation, Star\",\n",
    "        \"m10v_res30 = Simulation(simulation_name='m10v_res30', species=['star', 'dark'])\",\n",
    "    ]\n",
    "    code = \";\".join(commands);\n",
    "    stdin, stdout, stderr = ssh_client.exec_command(f'python -c \"print(\\'hi\\')\"')\n",
    "    # Read and print the output\n",
    "    for line in stdout.readlines():\n",
    "        print(line.strip())\n",
    "    # Close the SSH connection\n",
    "    ssh_client.close()\n",
    "\n",
    "\n",
    "ssh_into_remote()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/m10v_res030md/snapshot_600.z0.000.AHF_halos\n",
      "\n",
      "# in gizmo_analysis.gizmo_io.Read():\n",
      "* reading header from:  data/m10v_res030md/output/snapshot_600.0.hdf5\n",
      "  snapshot contains the following number of particles:\n",
      "    dark      (id = 1): 293563336 particles\n",
      "    dark2     (id = 2): 9654601 particles\n",
      "    gas       (id = 0): 293538508 particles\n",
      "    star      (id = 4): 19944 particles\n",
      "    blackhole (id = 5): 0 particles\n",
      "\n",
      "\n",
      "# in utilities.simulation.Snapshot():\n",
      "* reading:  data/m10v_res030md/snapshot_times.txt\n",
      "\n",
      "  using snapshot index = 600, redshift = 0.000\n",
      "\n",
      "\n",
      "# in gizmo_analysis.gizmo_io.Read():\n",
      "* reading header from:  data/m10v_res030md/output/snapshot_600.0.hdf5\n",
      "  snapshot contains the following number of particles:\n",
      "    dark      (id = 1): 293563336 particles\n",
      "    dark2     (id = 2): 9654601 particles\n",
      "    gas       (id = 0): 293538508 particles\n",
      "    star      (id = 4): 19944 particles\n",
      "    blackhole (id = 5): 0 particles\n",
      "\n",
      "* reading the following\n",
      "  species: ['star']\n",
      "  star properties: ['form.scalefactor', 'id', 'id.child', 'id.generation', 'mass', 'massfraction', 'position', 'velocity']\n",
      "\n",
      "* reading particles from:\n",
      "    snapshot_600.0.hdf5\n",
      "    snapshot_600.1.hdf5\n",
      "    snapshot_600.2.hdf5\n",
      "    snapshot_600.3.hdf5\n",
      "    snapshot_600.4.hdf5\n",
      "    snapshot_600.5.hdf5\n",
      "    snapshot_600.6.hdf5\n",
      "    snapshot_600.7.hdf5\n",
      "    snapshot_600.8.hdf5\n",
      "    snapshot_600.9.hdf5\n",
      "    snapshot_600.10.hdf5\n",
      "    snapshot_600.11.hdf5\n",
      "    snapshot_600.12.hdf5\n",
      "    snapshot_600.13.hdf5\n",
      "    snapshot_600.14.hdf5\n",
      "    snapshot_600.15.hdf5\n",
      "\n",
      "! cannot find MUSIC config file:  data/m10v_res030md/*/*.conf\n",
      "! missing cosmological parameters, assuming the following (from AGORA):\n",
      "  assuming omega_baryon = 0.0455\n",
      "  assuming sigma_8 = 0.807\n",
      "  assuming n_s = 0.961\n",
      "\n",
      "* checking sanity of particle properties\n",
      "! warning: star mass [min, max] = [0.011, 43.976]\n",
      "\n",
      "  cannot read file containing hosts coordinates\n",
      "  instead will assign hosts via iterative zoom on particle mass\n",
      "\n",
      "# in utilities.particle.get_center_positions():\n",
      "* assigning position for 1 center/host, via iterative zoom-in on star particle mass\n",
      "  host1 position = (3273.56, 3335.74, 3533.73) [kpc comoving]\n",
      "\n",
      "# in utilities.particle.get_center_velocities():\n",
      "* assigning velocity for 1 center/host, weighting star particles by mass\n",
      "  host1 velocity = (-22.2, -3.7, -6.3) [km / s]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['m10v_res030md_sim.pkl']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stellarutil import Simulation, Star\n",
    "import joblib\n",
    "SIMULATION = 'm10v_res030md' # The simulation to load\n",
    "sim = Simulation(simulation_name=SIMULATION)\n",
    "joblib.dump(sim, f'{SIMULATION}_sim.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the pkl file 'm10v_res030md_sim_dm.pkl': 13.61 GB\n",
      "Size of the directory '../data/m10v_res030md': 26.11 GB\n",
      "The pickle file is 52.13% of the size of the entire directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to convert bytes to gigabytes\n",
    "def bytes_to_gb(size_in_bytes):\n",
    "    return size_in_bytes / (1000 ** 3)  # 1 GB = 1000^3 bytes\n",
    "\n",
    "SIMULATION = 'm10v_res030md' # The simulation to load\n",
    "\n",
    "# Get the size of the pkl file\n",
    "file_path = f'{SIMULATION}_sim_dm.pkl'\n",
    "file_size = os.path.getsize(file_path)\n",
    "file_size_gb = bytes_to_gb(file_size)\n",
    "print(f\"Size of the pkl file '{file_path}': {file_size_gb:.2f} GB\")\n",
    "\n",
    "# Get the size of a directory\n",
    "directory_path = f'../data/{SIMULATION}'\n",
    "total_size = 0\n",
    "for dirpath, dirnames, filenames in os.walk(directory_path):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirpath, filename)\n",
    "        total_size += os.path.getsize(file_path)\n",
    "\n",
    "total_size_gb = bytes_to_gb(total_size)\n",
    "print(f\"Size of the directory '{directory_path}': {total_size_gb:.2f} GB\")\n",
    "\n",
    "print(f\"The pickle file is {round((file_size_gb / total_size_gb) * 100, 2)}% of the size of the entire directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.702\n",
      "0.702\n"
     ]
    }
   ],
   "source": [
    "from stellarutil import Simulation, getRemtoteData\n",
    "\n",
    "pickle_file = getRemtoteData()\n",
    "\n",
    "m10v_res030md = joblib.load(f\"m10v_res030md_sim.pkl\")\n",
    "print(m10v_res030md.h)\n",
    "# Doing it with way will tell Python what type to expect so auto complete can work in VS Code or other editors\n",
    "m10v_res250md: Simulation = joblib.load(f\"m10v_res030md_sim.pkl\")\n",
    "print(m10v_res250md.h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
